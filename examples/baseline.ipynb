{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline experiments\n",
    "This notebook contains the code to run a single baseline experiment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set up\n",
    "To use the custom modules defined in `src`, we first make sure that the working directory is the root folder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_folder = 'transformers-on-a-diet'\n",
    "while not os.getcwd().endswith(root_folder):\n",
    "    os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuration\n",
    "Specify the dataset, which portion of the data is used and the name that will be used to save the model in `results/raw/baseline`. We can then load the configuration."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Change parameters here\n",
    "dataset = 'mams'\n",
    "fraction = 0.1\n",
    "name = f'TEST_RUN_baseline_{dataset}_fr{fraction}'\n",
    "\n",
    "# Load the configuration\n",
    "from src.experiments import get_config\n",
    "\n",
    "config = get_config()\n",
    "data_config = config[dataset]\n",
    "model_config = config['baseline']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the data\n",
    "Load the training data from `datasets`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.data import Preprocessor\n",
    "\n",
    "preprocessor = Preprocessor()\n",
    "\n",
    "(trainX, trainY), _ = preprocessor.parse_train(dataset, data_config['train'], validation_split=1 - fraction)\n",
    "val_data = preprocessor.parse_test(dataset, data_config['val'])\n",
    "test_data = preprocessor.parse_test(dataset, data_config['test'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fit the model\n",
    "Load, compile and train the model using the data that has been loaded in the previous step.\n",
    "\n",
    "The model is trained via the regular `model.fit`, with the following additional callbacks to monitor performance and save the model:\n",
    "* `EvaluateCallback` evaluates the model on an additional dataset (the test dataset).\n",
    "* `ModelCheckpoint(..., save_weights_only=True, ...)` triggers the `SavableModel.save_weights()` to save the weights of the model. (`BaselineModel` is a subclass of `Savablemodel`)\n",
    "* `CSVLogger` logs the history to a CSV file. This includes the results from the `EvaluateCallback`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.models import BaselineModel\n",
    "from src.callbacks import EvaluateCallback\n",
    "# noinspection PyUnresolvedReferences\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "# Load the model\n",
    "model = BaselineModel(data_config['classes'])\n",
    "model.compile(optimizer=config['optimizer'], loss=config['loss'], metrics=data_config['metrics'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(trainX, trainY, batch_size=config['batch_size'], epochs=config['epochs'], validation_data=val_data, callbacks=[\n",
    "    EvaluateCallback(test_data),\n",
    "    ModelCheckpoint(\n",
    "        os.path.join(config['result_path'], 'checkpoints', name),\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_macro_f1',\n",
    "        mode='max'\n",
    "    ),\n",
    "    CSVLogger(os.path.join(config['result_path'], f'{name}.csv'))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quick methods\n",
    "Alternatively, the following methods are available to quickly perform an experiment.\n",
    "\n",
    "Please note: The second method generates name automatically (`baseline_{dataset}_fr{fraction}`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.experiments import baseline_experiment, baseline_experiments\n",
    "\n",
    "baseline_experiment(dataset, fraction, name)\n",
    "\n",
    "# To perform multiple experiments:\n",
    "baseline_experiments([dataset], [fraction], range(3))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
